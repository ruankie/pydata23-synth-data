---
marp: true
theme: uncover
class: invert
footer: Ruan Pretorius | October 2023
style: |
  section {
    font-size: 32px;
  }
---
![height:180px](../assets/pyconza.png)
# How to build a data pipeline without data
*Synthetic data generation and testing with Python*

---

## About me

##### Hi there, I'm Ruan Pretorius ğŸ‘‹

- ğŸ–¥ I am a data scientist at *[melio.ai](https://melio.ai/)*
- â˜• I turn coffee into data pipelines and AI
- ğŸ”— You can find me on GitHub *[@ruankie](https://github.com/ruankie)*
- âœ‰ï¸ Or contact me via email: *ruan@melio.ai*

---

## ğŸš Outline

- What are data pipelines and why do we need them?
- Challenges of building and testing data pipelines
- How to use synthetic data to test data pipelines
- Tools and methods to use when generating reliable synthetic data in Python
- Benefits and challenges of using synthetic data for testing data pipelines

---
# Tools

Used in this demo

# 

![height:100px](../assets/docker.svg) ![height:110px](../assets/postgres.png) ![height:110px](../assets/flyway.png) ![height:110px](../assets/python.png) 

---

## ğŸ› ï¸ What is a data pipeline?

- A data pipeline is a series of operations used to extract, load, transform, validate, or write data
- From various sources into a target file system, database, or data warehouse

---

## ğŸ” Data pipelines without real data

- Sometimes, we may not have access to the real data that we want to process in our data pipeline.
- It could be:
  - Sensitive or confidential and can't be shared
  - Not yet collected or available
  - Too large or complex to handle for initial testing

---

## ğŸ” Data pipelines without real data

- Without real data, it is challenging to:
  - Design the data model and schema
  - Develop the data extract, transform, and load (ETL) logic
  - Test the functionality and performance of the data pipeline
  - Debug and troubleshoot errors and issues

---

## ğŸ§ª Synthetic data to test data pipelines

- Synthetic data is artificially generated data that mimics the characteristics and behavior of real data
- Synthetic data can help us to test our data pipelines by:
  - Providing realistic sample data
  - Allowing  control of the size, shape, and distribution of the data
  - Enabling simulations of different scenarios and edge cases
  - Reducing the risk of exposing sensitive or confidential information

---

## ğŸ’ƒ Demo

- In this talk, I'll show you how you can create synthetic data
- Using a Python package called Faker
- And how to use Flyway to load the synthetic data into a Postgres database for repeatable deployments

---

## What are the benefits and challenges of using synthetic data for testing data pipelines?

- Some of the benefits of using synthetic data are:
  - It can speed up the development and testing process
  - It can increase the coverage and quality of testing
  - It can improve the scalability and reliability of the data pipeline
- Some of the challenges of using synthetic data are:
  - It may not capture all the nuances and variations of real data
  - It may introduce biases or errors in the synthetic data generation process
  - It may require additional effort and resources to create and maintain synthetic data

---

## What are some best practices and tips for creating and using synthetic data effectively?

- Some of the best practices and tips are:
  - Define the scope and purpose of your synthetic data
  - Use existing tools and libraries to generate synthetic data
  - Validate and verify your synthetic data against your real data schema and business rules
  - Document your synthetic data generation process and code
  - Keep your synthetic data up-to-date with your real data changes

---

## Summary

- In this talk, we learned how to build a data pipeline without real data using Python
- We discussed the challenges of building and testing data pipelines without real data
- We showed how we used synthetic data to test our data pipelines
- We demonstrated how we used Python packages such as Faker to generate realistic synthetic data
- We also showed how we used Flyway to load the synthetic data into a Postgres database

---

## Thank you!

- I hope you enjoyed this talk and learned something new
- If you have any questions or feedback, please feel free to contact me
- You can find the code and slides for this talk on GitHub

